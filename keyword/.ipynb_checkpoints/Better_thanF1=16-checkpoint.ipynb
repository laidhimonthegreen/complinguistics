{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "import nltk \n",
    "import gensim\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "morph = MorphAnalyzer()\n",
    "stops = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/скачиваем датасет НГ/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачаем данные в папке data и распакуем их\n",
    "PATH_TO_DATA = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(PATH_TO_DATA, file) for file in os.listdir(PATH_TO_DATA)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим файлы в один датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([pd.read_json(file, lines=True) for file in files][:1], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 5)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>keywords</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Многие интересуются, зачем нужна «Яблоку» молодежная фракция? Основной задачей «Молодежного «Яблока» является привлечение молодых людей к участию в выборах и деятельности партии. «Молодежное «Яблоко» работает более чем в 10 регионах. Единого руководства у нас нет, но мы стараемся координировать свою деятельность и периодически проводим акции на федеральном уровне.\\nМы ведем борьбу с обязательным воинским призывом. Военный – это профессия, а не обязанность. Молодые люди вправе сами распоряжаться своей жизнью и не терять целый год, отдавая государству «долг», который они у него не занимали. По мнению одного из ведущих специалистов в области оборонной политики Алексея Арбатова, переход на контрактную армию будет стоить лишь 2% военного бюджета.\\nТакже на федеральном уровне «Молодежное «Яблоко» проводило акции за освобождение политзаключенных и против вмешательства России во внутреннюю политику Украины.\\nРасскажу о московских активистах. Виктору Петрунину – 19 лет, он пришел к нам боль...</td>\n",
       "      <td>[яблоко, молодежь, молодежное яблоко]</td>\n",
       "      <td></td>\n",
       "      <td>\"Молодежное \"Яблоко\": оппозиционная деятельность становится опасной</td>\n",
       "      <td>http://www.ng.ru/ng_politics/2017-04-18/11_6976_apple.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Вчера «Газпром» снизил верхнюю планку прогноза собственной добычи газа в 2020 году. Через 12 лет концерн собирается добывать около 620–640 млрд. куб. м в год. При этом общее производство газа в стране, по расчетам холдинга, должно достичь 940 млрд. куб. м. Иными словами, треть добываемого объема, по мнению холдинга, должны будут обеспечить независимые производители. Эксперты не верят, что независимые компании смогут выйти на такие объемы добычи. Если расчеты «Газпрома» не оправдаются, то под ударом окажутся отечественные предприятия и население, которым придется сокращать потребление и смириться с новым витком цен. Иных путей покрытия возможного дефицита газа нет, так как вряд ли холдинг разорвет уже заключенные контракты на экспорт газа в другие страны. \\n«Газпром» к 2020 году планирует добывать 620–640 млрд. куб. м газа, сообщил вчера на форуме «ТЭК России в ХХI веке» глава управления по добыче газа, газового конденсата и нефти холдинга Валерий Минликаев. Тем самым он уточнил пре...</td>\n",
       "      <td>[газпром, газ]</td>\n",
       "      <td></td>\n",
       "      <td>\"Газпрома\" на всех не хватит</td>\n",
       "      <td>http://www.ng.ru/economics/2008-04-03/1_gazprom.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Долголетний труд Евгения Витковского на ниве перевода, а также в качестве редактора и антологиста известен многим. Но не все знают его как поэта и прозаика. В этом году уже вышла составленная им и Еленой Кистеровой антология  «Раздол туманов: Страницы шотландской гэльской поэзии XVII–XX вв.», а в апреле запланирован выход его романа «Протей, или Византийский кризис» (отрывок из романа читайте на с. 12). С \\n побеседовал \\n– Одна из таких книг только что вышла – «Раздол туманов. Страницы шотландской гэльской поэзии XVII–XX веков». Это стихи 29 поэтов, все в переводе с оригинала – моем и Елены Кистеровой. Работа заняла 10 лет, включая изучение языка. Она была упоительно интересной: до нас переводов из этой поэзии на русский не было вовсе. Сейчас должен выйти том стихотворений канадского классика Роберта Уильяма Сервиса, «канадского Киплинга», около 300 стихотворений. Кроме того, в Петербурге в производстве наш огромный трехтомный плод совместной работы – антология «Франция в сердце»....</td>\n",
       "      <td>[франсуа рабле, сервантес, шекспир, конан дойл, михаил булгаков, александр грин, борхес, босх, маркес, герман гессе, голландская живопись, гаргантюа и пантагрюэль, дон кихот, мастер и маргарита, москва, россия, история, поэзия, шотландия, баллада, пере]</td>\n",
       "      <td>Евгений Витковский о том, как Босх протягивает руку Шекспиру, \\r\\nи оба танцуют в пламени пожара в охваченном чумой средневековом городе</td>\n",
       "      <td>Бесконечная партия в четырехмерные  шахматы</td>\n",
       "      <td>http://www.ng.ru/person/2018-03-22/10_927_vitkovsky.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   content  \\\n",
       "0  Многие интересуются, зачем нужна «Яблоку» молодежная фракция? Основной задачей «Молодежного «Яблока» является привлечение молодых людей к участию в выборах и деятельности партии. «Молодежное «Яблоко» работает более чем в 10 регионах. Единого руководства у нас нет, но мы стараемся координировать свою деятельность и периодически проводим акции на федеральном уровне.\\nМы ведем борьбу с обязательным воинским призывом. Военный – это профессия, а не обязанность. Молодые люди вправе сами распоряжаться своей жизнью и не терять целый год, отдавая государству «долг», который они у него не занимали. По мнению одного из ведущих специалистов в области оборонной политики Алексея Арбатова, переход на контрактную армию будет стоить лишь 2% военного бюджета.\\nТакже на федеральном уровне «Молодежное «Яблоко» проводило акции за освобождение политзаключенных и против вмешательства России во внутреннюю политику Украины.\\nРасскажу о московских активистах. Виктору Петрунину – 19 лет, он пришел к нам боль...   \n",
       "1  Вчера «Газпром» снизил верхнюю планку прогноза собственной добычи газа в 2020 году. Через 12 лет концерн собирается добывать около 620–640 млрд. куб. м в год. При этом общее производство газа в стране, по расчетам холдинга, должно достичь 940 млрд. куб. м. Иными словами, треть добываемого объема, по мнению холдинга, должны будут обеспечить независимые производители. Эксперты не верят, что независимые компании смогут выйти на такие объемы добычи. Если расчеты «Газпрома» не оправдаются, то под ударом окажутся отечественные предприятия и население, которым придется сокращать потребление и смириться с новым витком цен. Иных путей покрытия возможного дефицита газа нет, так как вряд ли холдинг разорвет уже заключенные контракты на экспорт газа в другие страны. \\n«Газпром» к 2020 году планирует добывать 620–640 млрд. куб. м газа, сообщил вчера на форуме «ТЭК России в ХХI веке» глава управления по добыче газа, газового конденсата и нефти холдинга Валерий Минликаев. Тем самым он уточнил пре...   \n",
       "2  Долголетний труд Евгения Витковского на ниве перевода, а также в качестве редактора и антологиста известен многим. Но не все знают его как поэта и прозаика. В этом году уже вышла составленная им и Еленой Кистеровой антология  «Раздол туманов: Страницы шотландской гэльской поэзии XVII–XX вв.», а в апреле запланирован выход его романа «Протей, или Византийский кризис» (отрывок из романа читайте на с. 12). С \\n побеседовал \\n– Одна из таких книг только что вышла – «Раздол туманов. Страницы шотландской гэльской поэзии XVII–XX веков». Это стихи 29 поэтов, все в переводе с оригинала – моем и Елены Кистеровой. Работа заняла 10 лет, включая изучение языка. Она была упоительно интересной: до нас переводов из этой поэзии на русский не было вовсе. Сейчас должен выйти том стихотворений канадского классика Роберта Уильяма Сервиса, «канадского Киплинга», около 300 стихотворений. Кроме того, в Петербурге в производстве наш огромный трехтомный плод совместной работы – антология «Франция в сердце»....   \n",
       "\n",
       "                                                                                                                                                                                                                                                        keywords  \\\n",
       "0                                                                                                                                                                                                                          [яблоко, молодежь, молодежное яблоко]   \n",
       "1                                                                                                                                                                                                                                                 [газпром, газ]   \n",
       "2  [франсуа рабле, сервантес, шекспир, конан дойл, михаил булгаков, александр грин, борхес, босх, маркес, герман гессе, голландская живопись, гаргантюа и пантагрюэль, дон кихот, мастер и маргарита, москва, россия, история, поэзия, шотландия, баллада, пере]   \n",
       "\n",
       "                                                                                                                                    summary  \\\n",
       "0                                                                                                                                             \n",
       "1                                                                                                                                             \n",
       "2  Евгений Витковский о том, как Босх протягивает руку Шекспиру, \\r\\nи оба танцуют в пламени пожара в охваченном чумой средневековом городе   \n",
       "\n",
       "                                                                 title  \\\n",
       "0  \"Молодежное \"Яблоко\": оппозиционная деятельность становится опасной   \n",
       "1                                         \"Газпрома\" на всех не хватит   \n",
       "2                          Бесконечная партия в четырехмерные  шахматы   \n",
       "\n",
       "                                                          url  \n",
       "0  http://www.ng.ru/ng_politics/2017-04-18/11_6976_apple.html  \n",
       "1        http://www.ng.ru/economics/2008-04-03/1_gazprom.html  \n",
       "2    http://www.ng.ru/person/2018-03-22/10_927_vitkovsky.html  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(true_kws, predicted_kws):\n",
    "    assert len(true_kws) == len(predicted_kws)\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    jaccards = []\n",
    "    \n",
    "    for i in range(len(true_kws)):\n",
    "        true_kw = set(true_kws[i])\n",
    "        predicted_kw = set(predicted_kws[i])\n",
    "        \n",
    "        tp = len(true_kw & predicted_kw)\n",
    "        union = len(true_kw | predicted_kw)\n",
    "        fp = len(predicted_kw - true_kw)\n",
    "        fn = len(true_kw - predicted_kw)\n",
    "        \n",
    "        if (tp+fp) == 0:\n",
    "            prec = 0\n",
    "        else:\n",
    "            prec = tp / (tp + fp)\n",
    "        \n",
    "        if (tp+fn) == 0:\n",
    "            rec = 0\n",
    "        else:\n",
    "            rec = tp / (tp + fn)\n",
    "        if (prec+rec) == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = (2*(prec*rec))/(prec+rec)\n",
    "            \n",
    "        jac = tp / union\n",
    "        \n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        f1s.append(f1)\n",
    "        jaccards.append(jac)\n",
    "    print('Precision - ', round(np.mean(precisions), 2))\n",
    "    print('Recall - ', round(np.mean(recalls), 2))\n",
    "    print('F1 - ', round(np.mean(f1s), 2))\n",
    "    print('Jaccard - ', round(np.mean(jaccards), 2))\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что всё работает как надо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  1.0\n",
      "Recall -  1.0\n",
      "F1 -  1.0\n",
      "Jaccard -  1.0\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['keywords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/раньше тут были тупые решения (топ слов заголовка, частотные слова), но потом они всё равно будут повторяться в более умном виде, поэтому теперь их тут нет/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация, удаление стоп-слов и нормализация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "punct = punctuation+'«»—…“”*№–'\n",
    "stops = set(stopwords.words('russian'))\n",
    "\n",
    "def normalize(text):\n",
    "    \n",
    "    words = [word.strip(punct) for word in text.lower().split()]\n",
    "    words = [morph.parse(word)[0].normal_form for word in words if word and word not in stops]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_norm'] = data['content'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title_norm'] = data['title'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            [молодёжный, яблоко, оппозиционный, деятельность, становиться, опасный]\n",
       "1                                                                 [газпром, хватить]\n",
       "2                                      [бесконечный, партия, четырехмерный, шахматы]\n",
       "3    [экс-депутат, осудить, фальсификация, выбор, оказаться, член, боевой, братство]\n",
       "4                 [новый, москва, остаться, территория, экологический, безопасность]\n",
       "5                         [f1, гран-при, сша, пройти, четыре, машина, стопка, штраф]\n",
       "6                                [100, ведущий, политик, россия, февраль, 2018, год]\n",
       "7                                           [закон, культура, принимать, фон, арест]\n",
       "8                     [насколько, реальный, газовый, подоплёка, сирийский, конфликт]\n",
       "9                       [фсб, калужский, область, задержать, четверо, участник, иго]\n",
       "Name: title_norm, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title_norm'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Тупые\" способы стали менее тупыми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.11\n",
      "Recall -  0.22\n",
      "F1 -  0.14\n",
      "Jaccard -  0.08\n"
     ]
    }
   ],
   "source": [
    "# топ 10 частотных слов статьи\n",
    "evaluate(data['keywords'], data['content_norm'].apply(lambda x: [x[0] for x in Counter(x).most_common(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.13\n",
      "Recall -  0.14\n",
      "F1 -  0.12\n",
      "Jaccard -  0.07\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'],data['title_norm'].apply(lambda x: x[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление не-существительных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    \n",
    "    words = [word.strip(punct) for word in text.lower().split()]\n",
    "    words = [morph.parse(word)[0] for word in words if word and word not in stops]\n",
    "    words = [word.normal_form for word in words if word.tag.POS == 'NOUN'] \n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_norm'] = data['content'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [яблоко, акция, год, активист, деятельность, политика, власть, задача, молодая, человек]\n",
       "1               [миллиард, газа, год, куб, метр, газпром, добыча, производитель, страна, прогноз]\n",
       "2                [год, книга, роман, мир, перевод, стихотворение, читатель, жанр, поэзия, работа]\n",
       "3                     [ким, зинаида, видео, год, журналист, суд, дело, рубль, процесс, заседание]\n",
       "4                   [площадь, территория, москва, га, столица, тинао, развитие, парка, парк, год]\n",
       "5                    [гонка, команда, место, позиция, круг, чемпионат, пилот, бокс, заезд, льюис]\n",
       "6               [место, влияние, рф, позиция, глава, россия, президент, сергей, рейтинг, участие]\n",
       "7    [культура, закон, сфера, концепция, проект, изменение, сообщество, услуга, учреждение, дело]\n",
       "8                    [газопровод, сирия, год, турция, газа, россия, европа, катар, поток, проект]\n",
       "9                 [участник, рф, организация, государство, область, центр, связь, фсб, март, год]\n",
       "Name: content_norm, dtype: object"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['content_norm'].apply(lambda x: [x[0] for x in Counter(x).most_common(10)]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.13\n",
      "Recall -  0.25\n",
      "F1 -  0.16\n",
      "Jaccard -  0.09\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['content_norm'].apply(lambda x: [x[0] for x in Counter(x).most_common(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на цифры выше. 0.16 -- это то, что нам нужно превзойти. Поскольку я впервые вижу все эти методы, стоит поискать простой путь и посмотреть, нельзя ли просто выбрать другое количество самых частых слов после нормализации и получить хотя бы 0.17. \n",
    "Вот, например, для 5 слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.17\n",
      "Recall -  0.17\n",
      "F1 -  0.16\n",
      "Jaccard -  0.1\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['content_norm'].apply(lambda x: [x[0] for x in Counter(x).most_common(5)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall меньше, precision больше. А для 7?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.15\n",
      "Recall -  0.21\n",
      "F1 -  0.17\n",
      "Jaccard -  0.1\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['content_norm'].apply(lambda x: [x[0] for x in Counter(x).most_common(7)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Магия! Мы улучшили F1 на одну сотую (заносим это в список удачных улучшений в конце этой тетрадки).\n",
    "В будущем, возможно, тут будут более эффективные способы, но уже не все потеряно. \n",
    "Попробуем взять больше частотных слов: например, 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.12\n",
      "Recall -  0.27\n",
      "F1 -  0.16\n",
      "Jaccard -  0.09\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['content_norm'].apply(lambda x: [x[0] for x in Counter(x).most_common(12)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нет, увы. После еще нескольких попыток подставить разные числа в most_common было обнаружено, что лучший результат (F = 0.17) получается при количестве от 6 до 8. Дальше уже начинается F1 = 0.16, а дальше -- еще хуже. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на результаты для 7 (для \"качественного\" результата). \n",
    "Выглядит неплохо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [яблоко, акция, год, активист, деятельность, политика, власть]\n",
       "1                     [миллиард, газа, год, куб, метр, газпром, добыча]\n",
       "2            [год, книга, роман, мир, перевод, стихотворение, читатель]\n",
       "3                      [ким, зинаида, видео, год, журналист, суд, дело]\n",
       "4           [площадь, территория, москва, га, столица, тинао, развитие]\n",
       "5              [гонка, команда, место, позиция, круг, чемпионат, пилот]\n",
       "6               [место, влияние, рф, позиция, глава, россия, президент]\n",
       "7    [культура, закон, сфера, концепция, проект, изменение, сообщество]\n",
       "8                [газопровод, сирия, год, турция, газа, россия, европа]\n",
       "9       [участник, рф, организация, государство, область, центр, связь]\n",
       "Name: content_norm, dtype: object"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['content_norm'].apply(lambda x: [x[0] for x in Counter(x).most_common(7)]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем теперь добавить новые стоп-слова (на этот раз работая с 10 словами, как в коде из примера на семинаре). Немного изменим функцию \"normalize\" (добавим туда единицы измерения, времена года, слишком абстрактные существительные и тому подобное), а также уберем все слова короче трёх букв:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#да, я действительно просто убираю в \"стоппиз\" все слова, которые мне не нравятся, перезапускаю программу и\n",
    "#снова убираю слова, которые мне не нравятся\n",
    "#по крайней мере, когда-нибудь мне надоест и я пойму, зачем всё это автоматизировать\n",
    "new_stoppies = [\"газа\", \"год\", \"метр\", \"миллиард\", \"куб\", \"страна\", \"человек\", \"март\", \"январь\", \"апрель\", \n",
    "                \"май\", \"стихотворение\", \"читатель\", \"площадь\", \"территория\", \"развитие\",\n",
    "                \"место\", \"позиция\", \"глава\", \"концепция\", \"сфера\", \"организация\", \n",
    "                \"февраль\", \"июнь\", \"июль\", \"август\", \"сентябрь\", \"октябрь\", \"ноябрь\", \"декабрь\", \n",
    "                \"книга\", \"роман\", \"парка\", \"задача\", \"миллиард\", \"миллион\", \"молодая\", \"деятельность\",\n",
    "                \"учреждение\", \"сообщество\", \"участник\", \"том\", \"участие\", \"влияние\", \"услуга\", \"изменение\",\n",
    "                \"мир\", \"проект\", \"исследование\", \"фон\", \"срок\", \"житель\", \"область\", \"ячейка\", \"сообщение\",\n",
    "                \"балл\", \"жизнь\", \"процесс\", \"результат\", \"дело\", \"политик\", \"первое\", \"акт\",\n",
    "                \"александр\", \"сергей\", \"дарья\", \"виктор\", \"рейтинг\", \"департамент\", \"новое\", \"эксперт\",\n",
    "                \"политолог\", \"учёт\", \"система\", \"военный\", \"прошедшее\", \"подготовка\", \"округа\", \"добыча\",\n",
    "                \"производитель\", \"фильм\", \"зритель\", \"режиссёр\", \"связь\", \"мера\", \"президент\", \"переговоры\",\n",
    "                \"цена\", \"тысяча\", \"организатор\", \"женщина\", \"мужчина\", \"номинация\", \"речь\", \"решение\",\n",
    "                \"запрос\", \"постановление\", \"писательница\", \"герой\", \"произведение\", \"елена\", \"тихон\",\n",
    "                \"рост\", \"время\", \"центр\", \"данные\", \"интерес\", \"сторона\", \"кобальт\", \"компания\", \"агенство\",\n",
    "                \"объём\", \"институт\", \"лидер\", \"владимир\", \"андрей\", \"константин\", \"поставка\", \"исламист\",\n",
    "                \"регион\", \"состав\", \"машина\", \"ким\", \"журналист\", \"заседание\", \"свидетель\", \"фонд\", \n",
    "                \"союз\", \"вопрос\", \"внесение\", \"агенство\", \"пилотесса\", \"приз\", \"роль\", \"тема\", \"кирилл\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_new(text):\n",
    "           \n",
    "    words = [word.strip(punct) for word in text.lower().split()]\n",
    "    words = [morph.parse(word)[0] for word in words if word and word not in stops]\n",
    "    words = [word.normal_form for word in words if word.tag.POS == 'NOUN']\n",
    "    words = [word for word in words if word not in new_stoppies and len(word) > 2]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_norm2'] = data['content'].apply(normalize_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             [яблоко, акция, активист, политика, власть, выборы, уровень, россия, партия, борьба]\n",
       "1                 [газпром, прогноз, холдинг, расчёт, потребление, население, россия, концерн, слово, предприятие]\n",
       "2                              [перевод, жанр, поэзия, работа, мениппея, россия, москва, редактор, поэт, страница]\n",
       "3                    [зинаида, видео, суд, рубль, экспертиза, владивосток, участок, фальсификация, выборы, список]\n",
       "4                              [москва, столица, тинао, парк, власть, зона, мегаполис, земля, леса, строительство]\n",
       "5                                   [гонка, команда, круг, чемпионат, пилот, бокс, заезд, льюис, победа, ситуация]\n",
       "6                   [россия, вице-премьер, кандидат, форум, безопасность, алексей, ситуация, визит, канал, группа]\n",
       "7    [культура, закон, искусство, разработка, госдума, председатель, законодательство, характер, начало, перечень]\n",
       "8                              [газопровод, сирия, турция, россия, европа, катар, поток, иран, строительство, газ]\n",
       "9                                                                               [государство, фсб, эмиссар, сирия]\n",
       "Name: content_norm2, dtype: object"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['content_norm2'].apply(lambda x: [x[0] for x in Counter(x).most_common(10)]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.14\n",
      "Recall -  0.28\n",
      "F1 -  0.18\n",
      "Jaccard -  0.1\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['content_norm2'].apply(lambda x: [x[0] for x in Counter(x).most_common(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 совсем немного подросла -- теперь 0.18 (0.17 было практически сразу после удаления где-то 20 частых абстрактных понятий из ключевых слов), но хотелось сделать ещё чуть-чуть лучше). Понятно, что если сделать список абстрактных стоп-слов ещё больше, то точность может ещё улучшиться (это достаточно примитивный метод, но он работает). Занесем это в список удач в конце тетрадки тоже.\n",
    "Отдельно отмечу правила, по которым слова заносились в список стоп-слов: в него попадали личные имена, абстрактные  и не характерные для конкретных тем существительные (время, цена, вопрос, тема), различные меры, а также названия профессий. Возможно, если сделать обширные списки стоп-слов такого вида и игнорировать их при анализе, результат будет ещё лучше. \n",
    "\n",
    "Попробуем сделать однотипный список стоп-слов -- только имена.\n",
    "(Сначала пришлось загуглить \"список всех русских имен по алфавиту подряд через запятую\", потом сделать из этого список в Питоне, и вот он -- список всех русских имен по алфавиту подряд через запятую, в следующей функции (1340 с лишним слов, большая часть наверняка даже не найдется в корпусе). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#интересный факт -- кажется, юпитер ноутбук не вмещает в одну строку больше примерно тысячи элементов\n",
    "stop_names = ['абакум', 'абрам', 'абросим', 'аввакум', 'август', 'авдей', 'авдий', 'авель', 'авенир', 'аверий', 'аверкий', 'аверьян', 'авксентий', 'аврам', 'аврелиан', 'автоном', 'агап', 'агапий', 'агапит', 'агафангел', 'агафон', 'аггей', 'адам', 'адриан', 'азар', 'азарий', 'акакий', 'акила', 'аким', 'акиндин', 'акинф', 'акинфий', 'аксён', 'аксентий', 'александр', 'алексей', 'алексий', 'альберт', 'альфред', 'амвросий', 'амос', 'амфилохий', 'ананий', 'анастасий', 'анатолий', 'андрей', 'андриан', 'андрон', 'андроний', 'андроник', 'анект', 'анемподист', 'аникей', 'аникий', 'аникита', 'анисий', 'анисим', 'антиох', 'антип', 'антипа', 'антипий', 'антон', 'антонин', 'антроп', 'антропий', 'ануфрий', 'аполлинарий', 'аполлон', 'аполлос', 'ардалион', 'ардальон', 'ареф', 'арефий', 'арий', 'аристарх', 'аристид', 'аркадий', 'арнольд', 'арон', 'арсений', 'арсентий', 'артамон', 'артём', 'артемий', 'артур', 'архип', 'асаф', 'асафий', 'аскольд', 'афанасий', 'афиноген', 'афинодор', 'африкан', 'бажен', 'бенедикт', 'богдан', 'болеслав', 'бонифат', 'бонифатий', 'борис', 'борислав', 'бронислав', 'будимир', 'вавила', 'вадим', 'валентин', 'валериан', 'валерий', 'варлам', 'варламий', 'варнава', 'варсоноф', 'варсонофий', 'варфоломей', 'василий', 'вассиан', 'велизар', 'велимир', 'венедикт', 'вениамин', 'венцеслав', 'веньямин', 'викентий', 'виктор', 'викторий', 'викул', 'викула', 'вилен', 'виленин', 'вильгельм', 'виссарион', 'вит', 'виталий', 'витовт', 'витольд', 'владилен', 'владимир', 'владислав', 'владлен', 'влас', 'власий', 'вонифат', 'вонифатий', 'всеволод', 'всеслав', 'вукол', 'вышеслав', 'вячеслав', 'гавриил', 'гаврил', 'гаврила', 'галактион', 'гедеон', 'гедимин', 'геласий', 'гелий', 'геннадий', 'генрих', 'георгий', 'герасим', 'гервасий', 'герман', 'гермоген', 'геронтий', 'гиацинт', 'глеб', 'гораций', 'горгоний', 'гордей', 'гостомысл', 'гремислав', 'григорий', 'гурий', 'гурьян', 'давид', 'давыд', 'далмат', 'даниил', 'данил', 'данила', 'дементий', 'демид', 'демьян', 'денис', 'денисий', 'димитрий', 'диомид', 'дионисий', 'дмитрий', 'добромысл', 'добрыня', 'довмонт', 'доминик', 'донат', 'доримедонт', 'дормедонт', 'дормидбнт', 'дорофей', 'досифей', 'евгений', 'евграф', 'евграфий', 'евдоким', 'евлампий', 'евлогий', 'евмен', 'евмений', 'евсей', 'евстафий', 'евстахий', 'евстигней', 'евстрат', 'евстратий', 'евтихий', 'евфимий', 'егор', 'егорий', 'елизар', 'елисей', 'елистрат', 'елпидифор', 'емельян', 'епифан', 'епифаний', 'еремей', 'ермий', 'ермил', 'ермила', 'ермилий', 'ермолай', 'ерофей', 'ефим', 'ефимий', 'ефрем', 'ефремий', 'захар', 'захарий', 'зенон', 'зиновий', 'зосим', 'зосима', 'иаким', 'иакинф', 'иван', 'игнат', 'игнатий', 'игорь', 'иероним', 'измаил', 'измарагд', 'изосим', 'изот', 'изяслав', 'илларион', 'илиодор', 'илья', 'иннокентий', 'иоанн', 'йов', 'иона', 'иосафат', 'иосиф', 'ипат', 'ипатий', 'ипполит', 'ираклий', 'иринарх', 'ириней', 'иродион', 'исаак', 'исаакин', 'исай', 'исак', 'исакий', 'исидор', 'иустин', 'казимир', 'каллимах', 'каллиник', 'каллиопий', 'каллист', 'каллистрат', 'каллисфен', 'калуф', 'кандидий', 'кантидиан', 'капик', 'капитон', 'карион', 'карл', 'карп', 'кастрихий', 'касьян', 'ким', 'киприан', 'кир', 'кириак', 'кирик', 'кирилл', 'кирсан', 'клавдий', 'клим', 'климент', 'климентий', 'кондрат', 'кондратий', 'конон', 'конрад', 'константин', 'корней', 'корнелий', 'корнил', 'корнилий', 'ксенофонт', 'кузьма', 'куприян', 'лавр', 'лаврентий', 'ладимир', 'лазарь', 'ларион', 'лев', 'леон', 'леонард', 'леонид', 'леонтий', 'леопольд', 'логвин', 'лонгин', 'лука', 'лукан', 'лукьян', 'любим', 'любомир', 'любомысл', 'люциан', 'мавр', 'маврикий', 'мавродий', 'май', 'макар', 'макарий', 'македон', 'македоний', 'максим', 'максимиан', 'максимилиан', 'малх', 'мануил', 'марат', 'мардарий', 'мариан', 'марин', 'марк', 'маркел', 'маркиан', 'марлен', 'мартимьян', 'мартин', 'мартиниан', 'мартирий', 'мартин', 'мартьян', 'матвей', 'мелентий', 'мелетий', 'меркул', 'меркурий', 'мефодий', 'мечислав', 'милан', 'милен', 'милий', 'мина', 'минай', 'мирон', 'мирослав', 'мисаил', 'митрофан', 'митрофаний', 'михаил', 'михей', 'модест', 'моисей', 'мокей', 'мокий', 'мстислав', 'назар', 'назарий', 'наркис', 'натан', 'наум', 'нестер', 'нестор', 'нефёд', 'никандр', 'никанор', 'никита', 'никифор', 'никодим', 'николай', 'никон', 'нил', 'нифонт', 'олег', 'олимпий', 'онисим', 'онисифор', 'онуфрий', 'орест', 'осип', 'оскар', 'остап', 'остромир', 'павел', 'павлин', 'паисий', 'палладий', 'памфил', 'памфилий', 'панкрат', 'панкратий', 'пантелей', 'пантелеймон', 'панфил', 'парамон', 'пармен', 'парфён', 'парфений', 'парфентий', 'патрикей', 'патрикий', 'пафнутий', 'пахом', 'пахомий', 'перфилий', 'пётр', 'пимен', 'питирим', 'платон', 'полиевкт', 'полиект', 'поликарп', 'поликарпий', 'порфир', 'порфирий', 'потап', 'потапий', 'пров', 'прокл', 'прокоп', 'прокопий', 'прокофий', 'протас', 'протасий', 'прохор', 'радий', 'радим', 'радислав', 'радован', 'ратибор', 'ратмир', 'рафаил', 'роберт', 'родион', 'роман', 'ростислав', 'рубен', 'рувим', 'рудольф', 'руслан', 'рюрик', 'савва', 'савватей', 'савватий', 'савёл', 'савелий', 'саверий', 'савин', 'савиниан', 'сакердон', 'салтан', 'самбила', 'самсон', 'самсоний', 'самуил', 'светозар', 'свирид', 'святополк', 'святослав', 'себастьян', 'севастьян', 'северин', 'северьян', 'селиван', 'селивёрст', 'селифан', 'семён', 'семион', 'серапион', 'серафим', 'сергей', 'сигизмунд', 'сидор', 'сила', 'силан', 'силантий', 'силуян', 'сильван', 'сильвестр', 'симон', 'смарагд', 'созон', 'созонт', 'созонтий', 'сократ', 'соломон', 'сосипатр', 'софон', 'софоний', 'софрон', 'софроний', 'спартак', 'спиридон', 'спиридоний', 'станимир', 'стахий', 'станислав', 'степан', 'стоян', 'стратбник', 'сысой', 'тарас', 'твердислав', 'творимир', 'терентий', 'тертий', 'тигран', 'тигрий', 'тимофей', 'тимур', 'тит', 'тихон', 'тристан', 'трифилий', 'трифон', 'трофим', 'увар', 'ульян', 'устин', 'фабиан', 'фадей', 'фалалей', 'фатьян', 'фёдор', 'федос', 'федосей', 'федосий', 'федот', 'федотий', 'федул', 'феликс', 'фемистокл', 'феогност', 'феоктист', 'феофан', 'феофил', 'феофилакт', 'ферапонт', 'филарет', 'филат', 'филимон', 'филипий', 'филипп', 'филофей', 'фирс', 'флавиан', 'флавий', 'флегонт', 'флорентий', 'флорентин', 'флориан', 'фока', 'фома', 'фортунат', 'фотий', 'фридрих', 'фрол', 'харитон', 'харитоний', 'харлам', 'харламп', 'харлампий', 'хрисанф', 'христофор', 'эдуард', 'эмилий', 'эмиль', 'эммануил', 'эразм', 'эраст', 'эрнест', 'эрнст', 'ювеналий', 'юлиан', 'юлий', 'юрий', 'юстиниан', 'яким', 'яков', 'якуб', 'ян', 'януарий', 'ярополк', 'ярослав', 'августа', 'августина', 'авдотья', 'аврелия', 'аврея', 'аврора', 'агапа', 'агапия', 'агарь', 'агита', 'агафа', 'агафоклия', 'агафоника', 'агафья', 'агафия', 'аглаида', 'аглая', 'агна', 'агнесса', 'агния', 'аграфена', 'агриппина', 'ада', 'аделаида', 'аделина', 'аделла', 'адель', 'адельфина', 'адина', 'адолия', 'адриана', 'аза', 'азалия', 'азелла', 'аида', 'акилина', 'аксинья', 'аксиния', 'акулина', 'алевтина', 'александра', 'александрина', 'алексина', 'алёна', 'алина', 'алиса', 'алла', 'алфея', 'альберта', 'альбертина', 'альбина', 'альвина', 'альфия', 'амалия', 'амата', 'амелфа', 'анастасия', 'анатолия', 'ангела', 'ангелика', 'ангелина', 'анджела', 'андрея', 'андрона', 'андроника', 'анжелика', 'анисья', 'анисия', 'анна', 'антигона', 'антониана', 'антонида', 'антонина', 'антония', 'анфима', 'анфиса', 'анфия', 'анфуса', 'аполлинария', 'аполлония', 'апраксин', 'апрелия', 'апфия', 'аргентея', 'ариадна', 'арина', 'ария', 'арминия', 'арсения', 'артемида', 'артемия', 'аста', 'астра', 'афанасия', 'аэлита', 'беата', 'беатриса', 'белла', 'бенедикта', 'берта', 'бландина', 'богдана', 'божена', 'болеслава', 'борислава', 'бояна', 'бронислава', 'валентина', 'валенсия', 'валерия', 'ванда', 'васёна', 'василида', 'василина', 'василиса', 'василия', 'василла', 'васса', 'вацлава', 'вевея', 'велимира', 'велислава', 'венедикта', 'венуста', 'венцеслава', 'вера', 'вереника', 'вероника', 'вербния', 'веселина', 'веста', 'вестита', 'вива', 'вивея', 'вивиана', 'видина', 'викентия', 'викторина', 'виктбрия', 'вила', 'вилена', 'виленина', 'вильгельмина', 'виолетта', 'виргиния', 'виринея', 'вита', 'виталика', 'виталина', 'виталия', 'витольда', 'влада', 'владилена', 'владимира', 'владислава', 'владлена', 'воислава', 'воля', 'всеслава', 'гала', 'галата', 'галатея', 'гали', 'галина', 'галла', 'галя', 'гая', 'геласия', 'гемелла', 'гемина', 'гения', 'геннадия', 'геновефа', 'генриетта', 'георгина', 'гера', 'германа', 'гертруда', 'гея', 'глафира', 'гликерия', 'глорибза', 'голиндуха', 'гонеста', 'гонората', 'горгония', 'горислава', 'гортензия', 'градислава', 'грета', 'далила', 'даная', 'дарья', 'дария', 'дебора', 'деена', 'декабрена', 'денесия', 'денница', 'дея', 'диана', 'дигна', 'дина', 'диодора', 'дионина', 'дия', 'доброгнева', 'добромила', 'добромира', 'доброслава', 'доминика', 'домитилла', 'домна', 'домника', 'домникия', 'домнина', 'донара', 'доната', 'дора', 'дорофея', 'доса', 'досифея', 'дросида', 'дуклида', 'ева', 'евангелина', 'еванфия', 'евгения', 'евдокия', 'евдоксия', 'евлалия', 'евлампия', 'евмения', 'евминия', 'евника', 'евникия', 'евномия', 'евпраксия', 'евсевия', 'евстафия', 'евстолия', 'евтихия', 'евтропия', 'евфалия', 'евфимия', 'евфросиния', 'екатерина', 'елена', 'елизавета', 'еликонида', 'епистима', 'епистимия', 'ермиония', 'ефимия', 'ефимья', 'ефросиния', 'ефросинья', 'жанна', 'жозефина', 'зара', 'зарема', 'зарина', 'зари', 'зарина', 'звезда', 'земфира', 'зенона', 'зина', 'зинаида', \n",
    "     'зиновия', 'злата', 'зоя', 'ива', 'иванна', 'ида', 'идея', 'изабелла', 'изида', 'изольда', 'илария', 'илия', 'ильина', 'инга', 'инесса', 'инна', 'иоанна', 'иовилла', 'иола', 'иоланта', 'ипполита', 'ираида', 'ирина', 'ирма', 'исидора', 'ифигения', 'ия', 'каздоя', 'казимира', 'калерия', 'калида', 'калиса', 'каллиникия', 'каллиста', 'каллисфения', 'кама', 'камилла', 'кандида', 'капитолина', 'карина', 'каролина', 'касиния', 'келестина', 'керкира', 'кетевань', 'кикилия', 'кима', 'кира', 'кириакия', 'кириана', 'кирьяна', 'кирилла', 'клавдия', 'клара', 'клариса', 'клементина', 'клеопатра', 'конкордия', 'констанция', 'корнелия', 'кристина', 'ксанфиппа', 'ксения', 'купава', 'лавиния', 'лавра', 'лада', 'лариса', 'лаура', 'леда', 'лейла', 'лемира', 'ленина', 'леокадия', 'леонида', 'леонила', 'леонина', 'лебния', 'лея', 'лиана', 'ливия', 'лидия', 'лилиана', 'лилия', 'лина', 'лира', 'лия', 'лилия', 'лонгина', 'лора', 'лота', 'луиза', 'лукерья', 'лукиана', 'лукия', 'лукреция', 'любава', 'любовь', 'любомила', 'любомира', 'людмила', 'люцина', 'люция', 'мавра', 'магда', 'магдалина', 'магна', 'маина', 'майя', 'макрина', 'максима', 'малания', 'малинья', 'малина', 'мальвина', 'мамелфа', 'манефа', 'маргарита', 'мариам', 'мариамна', 'мариана', 'марианна', 'марьина', 'мариетта', 'марина', 'марионилла', 'мария', 'марья', 'марка', 'маркеллина', 'маркиана', 'марксина', 'марлена', 'марта', 'мартина', 'мартиниана', 'марфа', 'марья', 'мария', 'марьяна', 'марианна', 'мастридия', 'матильда', 'матрёна', 'матрона', 'мая', 'медея', 'мелания', 'меланья', 'мелитика', 'меркурия', 'мерона', 'милана', 'милена', 'милица', 'милия', 'милослава', 'милютина', 'мина', 'минна', 'минодора', 'мира', 'миропия', 'мирослава', 'мирра', 'митродора', 'михайлина', 'млада', 'модеста', 'моика', 'моника', 'мстислава', 'муза', 'нада', 'надежда', 'нана', 'наркисса', 'настасия', 'настасья', 'наталия', 'наталья', 'нелли', 'ненила', 'неонила', 'нида', 'ника', 'нила', 'нимфа', 'нимфодора', 'нина', 'нинель', 'новелла', 'нонна', 'ноэми', 'ноябрина', 'нунехия', 'оксана', 'октавия', 'октябрина', 'олдама', 'оливия', 'олимпиада', 'олимпиодора', 'олимпия', 'ольга', 'ольда', 'офелия', 'павла', 'павлина', 'паисия', 'паллада', 'паллидия', 'пальмира', 'параскева', 'патрикия', 'пелагея', 'перегрина', 'перпетуя', 'петра', 'петрина', 'петронилла', 'петрония', 'пиама', 'пинна', 'плакида', 'плакилла', 'платонида', 'победа', 'полактия', 'поликсена', 'поликсения', 'полина', 'поплия', 'правдина', 'прасковья', 'препедигна', 'прискилла', 'просдока', 'пульхерия', 'пульхерья', 'рада', 'радана', 'радислава', 'радмила', 'радомира', 'радосвета', 'радослава', 'радость', 'раиса', 'рафаила', 'рахиль', 'ревекка', 'ревмира', 'регина', 'рема', 'рената', 'римма', 'рипсимия', 'роберта', 'рогнеда', 'роза', 'розалина', 'розалинда', 'розалия', 'розина', 'роксана', 'романа', 'ростислава', 'русина', 'руслана', 'руфина', 'руфиниана', 'руфь', 'сабина', 'савватия', 'савелла', 'савина', 'саломея', 'сильвия', 'самона', 'сарра', 'сатира', 'светислава', 'светлана', 'светозара', 'святослава', 'севастьяна', 'северина', 'секлетея', 'секлетинья', 'селена', 'селестина', 'селина', 'серафима', 'сибилла', 'сильва', 'сильвана', 'сильвестра', 'сильвия', 'симона', 'синклитикия', 'сира', 'слава', 'снандулия', 'снежана', 'сола', 'соломонида', 'сосипатра', 'софрония', 'софья', 'софия', 'станислава', 'стелла', 'степанида', 'стефанида', 'стефания', 'сусанна', 'сюзанна', 'тавифа', 'таисия', 'таисья', 'тамара', 'тарасия', 'татьяна', 'текуса', 'тереза', 'тигрия', 'тихомира', 'тихослава', 'тома', 'томила', 'транквиллина', 'трифена', 'трофима', 'улита', 'ульяна', 'урбана', 'урсула', 'устина', 'устиния', 'устинья', 'фабиана', 'фавста', 'фавстина', 'фаина', 'фантика', 'феврония', 'февронья', 'федоза', 'федора', 'федосия', 'федосья', 'федотия', 'федотья', 'федула', 'фёкла', 'фекуса', 'феликса', 'фелица', 'фелицата', 'фелициана', 'фелицитата', 'фелиция', 'феогния', 'феодора', 'феодосия', 'феодота', 'феодотия', 'феодула', 'феодулия', 'феозва', 'феоктиста', 'феона', 'феонилла', 'фебния', 'феопистия', 'феосовия', 'феофания', 'феофила', 'фервуфа', 'фессалоника', 'фессалоникия', 'фетиния', 'фетинья', 'фея', 'фива', 'фивея', 'филарета', 'филиппа', 'филиппин', 'филомена', 'филонилла', 'филофея', 'фиста', 'флавия', 'флёна', 'флора', 'флорентина', 'флоренция', 'флориана', 'флорида', 'фомаида', 'фортуната', 'фотина', 'фотиния', 'фотинья', 'франциска', 'фрида', 'фридерика', 'хаврония', 'хариесса', 'хариса', 'харита', 'харитина', 'хиония', 'хриса', 'хрисия', 'христиана', 'христина', 'цвета', 'цветана', 'целестина', 'цецилия', 'шарлотта', 'шушаника', 'эвелина', 'эгина', 'эдит', 'элеонора', 'элисса', 'элла', 'эллада', 'эллина', 'элоиза', 'эльвира', 'эмилиана', 'эмилия', 'эмма', 'эннафа', 'эра', 'эрнеста', 'эрнестина', 'эсмеральда', 'эсфирь', 'юдифь', 'юлиана', 'юлиания', 'юлия', 'юния', 'юнона', 'юрия', 'юстина', 'ядвига', 'яна', 'янина', 'ярослава']\n",
    "\n",
    "def normalize_also_names(text):\n",
    "       \n",
    "    words = [word.strip(punct) for word in text.lower().split()]\n",
    "    words = [morph.parse(word)[0] for word in words if word and word not in stops]\n",
    "    words = [word.normal_form for word in words if word.tag.POS == 'NOUN']\n",
    "    words = [word for word in words if word not in stop_names and len(word) > 2]\n",
    "\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_norm_names'] = data['content'].apply(normalize_also_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [яблоко, акция, год, активист, деятельность, политика, власть, задача, молодая, человек]\n",
       "1                [миллиард, газа, год, куб, метр, газпром, добыча, производитель, страна, прогноз]\n",
       "2          [год, книга, мир, перевод, стихотворение, читатель, жанр, поэзия, работа, произведение]\n",
       "3             [видео, год, журналист, суд, дело, рубль, процесс, заседание, экспертиза, свидетель]\n",
       "4                [площадь, территория, москва, столица, тинао, развитие, парка, парк, год, регион]\n",
       "5                     [гонка, команда, место, позиция, круг, чемпионат, пилот, бокс, заезд, льюис]\n",
       "6    [место, влияние, позиция, глава, россия, президент, рейтинг, участие, исследование, институт]\n",
       "7     [культура, закон, сфера, концепция, проект, изменение, сообщество, услуга, учреждение, дело]\n",
       "8                     [газопровод, сирия, год, турция, газа, россия, европа, катар, поток, проект]\n",
       "9              [участник, организация, государство, область, центр, связь, фсб, март, год, ячейка]\n",
       "Name: content_norm_names, dtype: object"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['content_norm_names'].apply(lambda x: [x[0] for x in Counter(x).most_common(10)]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.13\n",
      "Recall -  0.25\n",
      "F1 -  0.16\n",
      "Jaccard -  0.09\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['content_norm_names'].apply(lambda x: [x[0] for x in Counter(x).most_common(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ничего не получилось хорошего. \n",
    "Теоретически можно считать это неудачной попыткой, но это скорее модификация удачного способа со списками. Тем не менее, отправим это в итоговый список результатов как неудачу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем понастраивать tfidf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_norm_str'] = data['content_norm'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно заодно сделать нграммы\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(data['content_norm_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем наши тексты в векторы, где на позиции i стоит tfidf коэффициент слова i из словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_vectors = tfidf.transform(data['content_norm_str'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсортируем векторы текстов по этим коэффициентам и возьмем топ-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сортировка по убыванию, поэтому нужно развернуть список\n",
    "keywords = [[id2word[w] for w in top] for top in texts_vectors.toarray().argsort()[:,:-11:-1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.12\n",
      "Recall -  0.24\n",
      "F1 -  0.15\n",
      "Jaccard -  0.09\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['яблоко',\n",
       "  'активист',\n",
       "  'акция',\n",
       "  'дарья',\n",
       "  'деятельность',\n",
       "  'молодая человек',\n",
       "  'политика',\n",
       "  'виктор',\n",
       "  'выборы',\n",
       "  'силовик'],\n",
       " ['миллиард куб',\n",
       "  'куб метр',\n",
       "  'куб',\n",
       "  'газпром',\n",
       "  'газа',\n",
       "  'миллиард',\n",
       "  'добыча',\n",
       "  'метр',\n",
       "  'добыча газа',\n",
       "  'холдинг'],\n",
       " ['роман',\n",
       "  'книга',\n",
       "  'жанр',\n",
       "  'стихотворение',\n",
       "  'перевод',\n",
       "  'читатель',\n",
       "  'год',\n",
       "  'поэзия',\n",
       "  'произведение',\n",
       "  'том']]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.12\n",
      "Recall -  0.24\n",
      "F1 -  0.15\n",
      "Jaccard -  0.09\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В текущем виде tfidf показывает результаты даже хуже, чем 0.16 (неясно, почему -- в ноутбуке из классной работы вроде всё работало). Попробуем улучшить: удалим биграммы (видно, что \"миллиард куб\" и \"молодая человек\" -- так себе варианты) и откажемся от ограничения min_df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.13\n",
      "Recall -  0.26\n",
      "F1 -  0.17\n",
      "Jaccard -  0.1\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,1), min_df=0)\n",
    "tfidf.fit(data['content_norm_str'])\n",
    "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}\n",
    "texts_vectors = tfidf.transform(data['content_norm_str'])\n",
    "keywords = [[id2word[w] for w in top] for top in texts_vectors.toarray().argsort()[:,:-11:-1]] \n",
    "evaluate(data['keywords'], keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 = 0.17. Получилось, заносим в отчёт в конце файла. \n",
    "Попробуем ещё поиграть с настройками. Добавим max_df = 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.13\n",
      "Recall -  0.26\n",
      "F1 -  0.17\n",
      "Jaccard -  0.1\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,1), min_df=0, max_df = 0.5)\n",
    "tfidf.fit(data['content_norm_str'])\n",
    "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}\n",
    "texts_vectors = tfidf.transform(data['content_norm_str'])\n",
    "keywords = [[id2word[w] for w in top] for top in texts_vectors.toarray().argsort()[:,:-11:-1]] \n",
    "evaluate(data['keywords'], keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ничего не получилось. \n",
    "Ещё один банальный способ -- поиграем с количеством ключевых слов. В прошлый раз хорошо работал, например, на 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.15\n",
      "Recall -  0.2\n",
      "F1 -  0.16\n",
      "Jaccard -  0.1\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=5)\n",
    "tfidf.fit(data['content_norm_str'])\n",
    "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}\n",
    "texts_vectors = tfidf.transform(data['content_norm_str'])\n",
    "keywords = [[id2word[w] for w in top] for top in texts_vectors.toarray().argsort()[:,:-8:-1]] \n",
    "evaluate(data['keywords'], keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз тоже работает чуть получше, но всё же не дотягивает до 0.17 при базовых настройках. Попробуем при удачных настройках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.16\n",
      "Recall -  0.22\n",
      "F1 -  0.18\n",
      "Jaccard -  0.11\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,1), min_df=0)\n",
    "tfidf.fit(data['content_norm_str'])\n",
    "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}\n",
    "texts_vectors = tfidf.transform(data['content_norm_str'])\n",
    "keywords = [[id2word[w] for w in top] for top in texts_vectors.toarray().argsort()[:,:-8:-1]] \n",
    "evaluate(data['keywords'], keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, получилось ещё немного увеличить F1 -- до 0.18. Кажется, уже удалось три раза получить чуть-чуть лучший результат, но попробуем что-то новое.\n",
    "\n",
    "Посмотрим на уже готовые решения и проверим, можно ли их улучшить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gensim keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.11\n",
      "Recall -  0.14\n",
      "F1 -  0.12\n",
      "Jaccard -  0.07\n"
     ]
    }
   ],
   "source": [
    "from gensim.summarization import keywords \n",
    "\n",
    "data_list = data['content_norm_str'].tolist()\n",
    "gkeys = [] \n",
    "\n",
    "for i in data_list:\n",
    "    gkeys.append(keywords(i, words = 7, pos_filter = (\"NN\")).split(\"\\n\"))  \n",
    "    \n",
    "\n",
    "evaluate(data['keywords'], gkeys)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат не очень хороший, заметно ниже даже, чем 0.16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['яблоко', 'акция', 'год', 'активист', 'деятельность', 'политика', 'власть'],\n",
       " ['газпром', 'добыча газа год', 'миллиард', 'производитель', 'холдинг'],\n",
       " ['год', 'книга', 'роман', 'мир', 'перевод', 'читатель', 'стихотворение'],\n",
       " ['зинаида ким', 'журналист видео', 'год', 'летие', 'экспертиза'],\n",
       " ['москва', 'территория', 'площадь', 'парка', 'столица', 'парк', 'тинао'],\n",
       " ['гонка', 'команда', 'позиция', 'место', 'круг', 'бокс', 'чемпионат'],\n",
       " ['позиция', 'влияние глава', 'место', 'сергеи', 'россия', 'участие'],\n",
       " ['культура',\n",
       "  'закон',\n",
       "  'дело',\n",
       "  'сообщество',\n",
       "  'концепция',\n",
       "  'сфера',\n",
       "  'изменение'],\n",
       " ['год', 'сирия', 'турция европа газопровод', 'газа', 'россия'],\n",
       " ['территория сирия сообщение', 'организация государство область центр']]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkeys[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что многие из ключевых слов -- это строки, склеенные из нескольких существительных, которые вряд ли будут хорошими ключевыми словами. Разобьем их на отдельные слова. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.14\n",
      "Recall -  0.19\n",
      "F1 -  0.15\n",
      "Jaccard -  0.09\n"
     ]
    }
   ],
   "source": [
    "gkeys2 = []\n",
    "for i in gkeys: \n",
    "    a = [f for f in i if \" \" not in f]\n",
    "    d = [f.split() for f in i if \" \" in f]\n",
    "    d2 = []\n",
    "    for el in d:\n",
    "        for f in el:\n",
    "            a.append(f) \n",
    "    gkeys2.append(a)\n",
    "      \n",
    "evaluate(data['keywords'], gkeys2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже лучше, но все равно не получается побить baseline. Попробуем взять наш список стоп-слов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.18\n",
      "Recall -  0.18\n",
      "F1 -  0.17\n",
      "Jaccard -  0.1\n"
     ]
    }
   ],
   "source": [
    "#еще одна инкарнация gkeys\n",
    "gkeys3 = []\n",
    "\n",
    "for i in gkeys2:\n",
    "    t = [f for f in i if f not in new_stoppies]\n",
    "    gkeys3.append(t)\n",
    "    \n",
    "evaluate(data['keywords'], gkeys3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Со стоп-словами gensim работает, но все еще показывает результат хуже, чем даже для частотных слов. Посмотрим на эти слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['яблоко', 'акция', 'активист', 'политика', 'власть'],\n",
       " ['газпром', 'холдинг'],\n",
       " ['перевод'],\n",
       " ['летие', 'экспертиза', 'зинаида', 'видео'],\n",
       " ['москва', 'столица', 'парк', 'тинао'],\n",
       " ['гонка', 'команда', 'круг', 'бокс', 'чемпионат'],\n",
       " ['сергеи', 'россия'],\n",
       " ['культура', 'закон'],\n",
       " ['сирия', 'россия', 'турция', 'европа', 'газопровод'],\n",
       " ['сирия', 'государство']]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkeys3[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, проблема в том, что теперь списки слишком невелики. Попробуем увеличить списки слов, которые мы берем изначально, а также убрать имена из списка ключевых слов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.14\n",
      "Recall -  0.24\n",
      "F1 -  0.17\n",
      "Jaccard -  0.1\n"
     ]
    }
   ],
   "source": [
    "ngkeys = []\n",
    "for i in data_list:\n",
    "    try:\n",
    "        ngkeys.append(keywords(i, words = 12, pos_filter = (\"NN\")).split(\"\\n\"))\n",
    "    except IndexError:\n",
    "        ngkeys.append(keywords(i, words = 9, pos_filter = (\"NN\")).split(\"\\n\"))\n",
    "    \n",
    "ngkeys2 = []\n",
    "for i in ngkeys: \n",
    "    a = [f for f in i if \" \" not in f]\n",
    "    d = [f.split() for f in i if \" \" in f]\n",
    "    d2 = []\n",
    "    for el in d:\n",
    "        for f in el:\n",
    "            a.append(f) \n",
    "    ngkeys2.append(a) \n",
    "\n",
    "ngkeys3 = []\n",
    "\n",
    "for i in ngkeys2:\n",
    "    t = [f for f in i if f not in new_stoppies and f not in stop_names]\n",
    "    ngkeys3.append(t)\n",
    "    \n",
    "evaluate(data['keywords'], ngkeys3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['яблоко', 'акция', 'политика', 'власть', 'россия', 'активист', 'выборы'],\n",
       " ['газпром', 'потребление', 'прогноз', 'расчет', 'холдинг'],\n",
       " ['перевод', 'герои', 'работа', 'жанр', 'мениппея'],\n",
       " ['летие', 'экспертиза', 'рубль', 'видео'],\n",
       " ['москва', 'парк', 'власть', 'тинао', 'столица'],\n",
       " ['гонка',\n",
       "  'команда',\n",
       "  'круг',\n",
       "  'бокс',\n",
       "  'чемпионат',\n",
       "  'пилот',\n",
       "  'заезд',\n",
       "  'дженсон'],\n",
       " ['сергеи', 'россия', 'реитинг'],\n",
       " ['культура', 'закон', 'законодательство', 'учет'],\n",
       " ['сирия',\n",
       "  'россия',\n",
       "  'строительство',\n",
       "  'турция',\n",
       "  'европа',\n",
       "  'газопровод',\n",
       "  'поток',\n",
       "  'катар',\n",
       "  'иран'],\n",
       " ['государство', 'фсб', 'эмиссар', 'сирия']]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngkeys3[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошо настроить gensim не удалось, а без списков стоп-слов он работает и вовсе плохо. Заносим в неудачи/удачи (baseline все-таки побит). Еще один интересный баг генсима -- он заменяет \"и\" на \"й\" (сергеи, реитинг), как с этим справляться -- пока непонятно.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rutermextractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем ещё один существующий инструмент -- rutermextractor (https://github.com/igor-shevchenko/rutermextract) (в том числе вместе с нашими стоп-словами и метриками). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rutermextract import TermExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "termkeys = []\n",
    "termkeys_clear = []\n",
    "\n",
    "term_extractor = TermExtractor()\n",
    "for i in data_list: \n",
    "    lst = []\n",
    "    for term in term_extractor(i, limit=9):\n",
    "        lst.append(str(term.normalized))\n",
    "    termkeys.append(lst)\n",
    "    termkeys_clear.append([i for i in lst if i not in new_stoppies and len(i) > 2 \n",
    "                           and i not in stop_names and \" \" not in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.12\n",
      "Recall -  0.22\n",
      "F1 -  0.15\n",
      "Jaccard -  0.09\n",
      "Precision -  0.17\n",
      "Recall -  0.21\n",
      "F1 -  0.18\n",
      "Jaccard -  0.11\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], termkeys)\n",
    "evaluate(data['keywords'], termkeys_clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rutermextractor работает примерно так же, как gensim и tfidf (0.15 без помощи дополнительных списков стоп-слов и 0.18 с помощью). Впрочем, есть и плюсы -- пока что это один из самых простых в применении инструментов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['яблоко', 'акция', 'активист', 'политика', 'власть', 'уровень'],\n",
       " ['газпром', 'холдинг'],\n",
       " ['перевод', 'жанр', 'россия'],\n",
       " ['видео', 'экспертиза', 'суд', 'рубль'],\n",
       " ['москва', 'тинао', 'столица', 'парк'],\n",
       " ['гонка', 'команда', 'круг', 'чемпионат', 'пилот', 'бокс', 'ситуация'],\n",
       " ['россия'],\n",
       " ['культура', 'закон'],\n",
       " ['газопровод', 'сирия', 'турция', 'россия', 'катар', 'европа', 'поток'],\n",
       " ['эмиссар'],\n",
       " ['стихомант', 'старик', 'журибеда', 'казак', 'сэмена', 'отец', 'голос'],\n",
       " ['жильё', 'население', 'спрос', 'строительство'],\n",
       " ['театр', 'кино', 'аудитория'],\n",
       " ['фестиваль',\n",
       "  'революция',\n",
       "  'ленин',\n",
       "  'награда',\n",
       "  'сахалин',\n",
       "  'миронов',\n",
       "  'троцкий'],\n",
       " ['фёдоров', 'вечер', 'балашов', 'виктория'],\n",
       " ['франция', 'макрон', 'дриана', 'россия', 'резолюция', 'париж'],\n",
       " ['суд', 'юкос', 'право', 'минюст', 'еспч'],\n",
       " ['электромобиль', 'аккумулятор', 'автомобиль', 'электрокар'],\n",
       " ['церемония', 'статуэтка', 'актёр'],\n",
       " ['трасса', 'нюрбургринг', 'шмитц', 'гонка', 'автомобиль']]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termkeys_clear[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rake-nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как работает rake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "#на больших объёмах он сатанеет и выдаёт поток сознания, попробуем от 1 до 3\n",
    "r = Rake(min_length=1, max_length=3)\n",
    "\n",
    "#попробуем на маленькой части корпуса с ограничением по словам\n",
    "for i in data_list[0:5]:\n",
    "    r.extract_keywords_from_text(str(i))\n",
    "    print (r.get_ranked_phrases())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rake предпочитает не работать никак. Можно его понять. На некоторых текстах он всё же выдает небольшие ключевые фразы, но они слишком бессмысленные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PKE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще один уже созданный извлекатель ключевых слов: https://github.com/boudinfl/pke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-301-4fc95205ca75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate_weighting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mkeyphrases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pke/unsupervised/graph_based/topicrank.py\u001b[0m in \u001b[0;36mcandidate_weighting\u001b[0;34m(self, threshold, method, heuristic)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;31m# build the topic graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_topic_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# compute the word scores using random walk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pke/unsupervised/graph_based/topicrank.py\u001b[0m in \u001b[0;36mbuild_topic_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mp_j\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                                 \u001b[0mgap\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexical_form\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mgap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     def candidate_weighting(self,\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "#в процессе он выдавал такую ошибку: https://github.com/fastai/fastai/issues/632, пришлось догрузить еще вещей\n",
    "\n",
    "import pke\n",
    "extractor = pke.unsupervised.TopicRank()\n",
    "text = data_list[0]\n",
    "\n",
    "keyphrases = []\n",
    "\n",
    "#для одного результат был, попробуем хотя бы для двух\n",
    "for i in data_list[0:2]:\n",
    "    extractor.load_document(input=i)\n",
    "    extractor.candidate_selection()\n",
    "    extractor.candidate_weighting()\n",
    "    keyphrases.append(extractor.get_n_best(n=5))\n",
    "\n",
    "keyphrases\n",
    "\n",
    "#выдает ошибку ZeroDivisionError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если бы времени было чуть больше, можно было бы починить то, что на двух и больше текстах он ломается, но, похоже, не сегодня. Записываем в неудачные попытки. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итог:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удачные попытки.\n",
    "\n",
    "1. Изменение числа частотных слов -- удачная попытка и ряд неудачных.\n",
    "F1 = 0.17 при 6-8 словах, меньше при 5 и меньше, а также при 9 и больше. \n",
    "\n",
    "2. Создание списка стоп-слов вручную, включая абстрактные термины.\n",
    "F1 = 0.18.\n",
    "\n",
    "3. Изменение настроек tf-idf (удаление биграмм и отказ от min_df).\n",
    "F1 = 0.17\n",
    "При сокращении количества ключевых слов до 7 F1 = 0.18 (кажется, лучше выбирать 7-8 ключевых слов вместо 10, судя по опыту с tf-idf и частотными словами). \n",
    "Также неудачная попытка при настройке max_df, который не влиял на F1 (F1 = 0.17 при сохранении настроек для энграмм и min_df). \n",
    "\n",
    "Непонятные попытки.\n",
    "1. gensim -- лучший результат без привлечения уже использованных методов F1 = 0.15, c ними -- F1 = 0.17 (использовались стоп-слова). \n",
    "2. rutermextractor -- лучший результат без привлечения уже использованных методов F1 = 0.15, c ними -- F1 = 0.18 (использовались стоп-слова). \n",
    "\n",
    "Неудачные попытки. \n",
    "1. Создание списка стоп-слов в виде списка русских имён.\n",
    "F1 = 0.16\n",
    "2. Попытки работать с обычной версией rake.\n",
    "Вообще не выдает ничего похожего на адекватный ответ, показалось, что даже считать метрики бессмысленно. \n",
    "3. Попытки работать с PKE.\n",
    "На одном тексте выдает что-то немного похожее на ключевые слова (адекватнее, чем rake), но сделать для нескольких текстов не получилось (возможно, просто не успела, вряд ли там что-то очень сложное). \n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
